{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsnet_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuickLearner171998/CapsNet/blob/master/capsnet_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Ny1TiIq_Mk",
        "colab_type": "code",
        "outputId": "50b84cea-abee-47d1-e1dd-16d9c61cbaa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fad8N1QAq_Lk",
        "colab_type": "code",
        "outputId": "cc6d6dd6-d63b-422c-c265-2705362b40ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "%cd gdrive\n",
        "%cd 'My Drive'\n",
        "%cd 'MY Projects'\n",
        "%cd 'EEE lop'\n",
        "%cd 'tensorflow_implementation'\n",
        "!ls\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n",
            "/content/gdrive/My Drive\n",
            "/content/gdrive/My Drive/MY Projects\n",
            "/content/gdrive/My Drive/MY Projects/EEE lop\n",
            "/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation\n",
            "'capsnet tf.ipynb'   data     results\t\t  Try-1\n",
            " capsnet_tf.py\t     logdir   tensorboard.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcHekIQBo9Sm",
        "colab_type": "code",
        "outputId": "087eecf5-e8de-4b98-c366-c102d2647222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "import scipy\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_1fObfoM4V",
        "colab_type": "text"
      },
      "source": [
        "# Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp6y0HhQoDyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist_kannada(batch_size, is_training=True):\n",
        "    if is_training:\n",
        "        fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_train-idx3-ubyte')\n",
        "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "        trainX = loaded[16:].reshape((60000, 28, 28, 1)).astype(np.float32)\n",
        "\n",
        "        fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/y_kannada_MNIST_train-idx1-ubyte')\n",
        "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "        trainY = loaded[8:].reshape((60000)).astype(np.int32)\n",
        "\n",
        "        trX = trainX[:55000] / 255.\n",
        "        trY = trainY[:55000]\n",
        "\n",
        "        valX = trainX[55000:, ] / 255.\n",
        "        valY = trainY[55000:]\n",
        "\n",
        "        num_tr_batch = 55000 // batch_size\n",
        "        num_val_batch = 5000 // batch_size\n",
        "\n",
        "        return trX, trY, num_tr_batch, valX, valY, num_val_batch\n",
        "    else:\n",
        "        \n",
        "        # test on 60K dataset\n",
        "        #fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_test-idx3-ubyte')\n",
        "        \n",
        "        # test on DIG 10K \n",
        "        fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Dig_MNIST/X_dig_MNIST-idx3-ubyte.gz (Unzipped Files)/X_dig_MNIST-idx3-ubyte')\n",
        "        \n",
        "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "        n_test_img = ((len(loaded)-16))//(28*28)\n",
        "        teX = loaded[16:].reshape((n_test_img, 28, 28, 1)).astype(np.float)\n",
        "        \n",
        "        # test on 60K\n",
        "        #fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/y_kannada_MNIST_test-idx1-ubyte')\n",
        "        \n",
        "        # test on 10K\n",
        "        fd = open('/content/gdrive/My Drive/MY Projects/EEE lop/tensorflow_implementation/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Dig_MNIST/y_dig_MNIST-idx1-ubyte.gz (Unzipped Files)/y_dig_MNIST-idx1-ubyte')\n",
        "        \n",
        "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "        teY = loaded[8:].reshape((n_test_img)).astype(np.int32)\n",
        "\n",
        "        num_te_batch = n_test_img // batch_size\n",
        "        return teX / 255., teY, num_te_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_data(batch_size, is_training=True, one_hot=False):\n",
        "    return load_mnist_kannada(batch_size, is_training)\n",
        "    \n",
        "\n",
        "def get_batch_data(batch_size, num_threads):\n",
        "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_mnist_kannada(batch_size, is_training=True)\n",
        "    data_queues = tf.train.slice_input_producer([trX, trY])\n",
        "    X, Y = tf.train.shuffle_batch(data_queues, num_threads=num_threads,\n",
        "                                  batch_size=batch_size,\n",
        "                                  capacity=batch_size * 64,\n",
        "                                  min_after_dequeue=batch_size * 32,\n",
        "                                  allow_smaller_final_batch=False)\n",
        "\n",
        "    return(X, Y)\n",
        "\n",
        "\n",
        "def save_images(imgs, size, path):\n",
        "    '''\n",
        "    Args:\n",
        "        imgs: [batch_size, image_height, image_width]\n",
        "        size: a list with tow int elements, [image_height, image_width]\n",
        "        path: the path to save images\n",
        "    '''\n",
        "    imgs = (imgs + 1.) / 2  # inverse_transform\n",
        "    return(scipy.misc.imsave(path, mergeImgs(imgs, size)))\n",
        "\n",
        "\n",
        "def mergeImgs(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    imgs = np.zeros((h * size[0], w * size[1], 3))\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx // size[1]\n",
        "        imgs[j * h:j * h + h, i * w:i * w + w, :] = image\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "# For version compatibility\n",
        "def reduce_sum(input_tensor, axis=None, keepdims=False):\n",
        "    try:\n",
        "        return tf.reduce_sum(input_tensor, axis=axis, keepdims=keepdims)\n",
        "    except:\n",
        "        return tf.reduce_sum(input_tensor, axis=axis, keep_dims=keepdims)\n",
        "\n",
        "\n",
        "# For version compatibility\n",
        "def softmax(logits, axis=None):\n",
        "    try:\n",
        "        return tf.nn.softmax(logits, axis=axis)\n",
        "    except:\n",
        "        return tf.nn.softmax(logits, dim=axis)\n",
        "\n",
        "\n",
        "def get_shape(inputs, name=None):\n",
        "    name = \"shape\" if name is None else name\n",
        "    with tf.name_scope(name):\n",
        "        static_shape = inputs.get_shape().as_list()\n",
        "        dynamic_shape = tf.shape(inputs)\n",
        "        shape = []\n",
        "        for i, dim in enumerate(static_shape):\n",
        "            dim = dim if dim is not None else dynamic_shape[i]\n",
        "            shape.append(dim)\n",
        "        return(shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKpCvqBGoWLL",
        "colab_type": "text"
      },
      "source": [
        "# CapsLayer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkKkxQriobw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "License: Apache-2.0\n",
        "Author: Huadong Liao\n",
        "E-mail: naturomics.liao@gmail.com\n",
        "\"\"\"\n",
        "\n",
        "epsilon = 1e-9\n",
        "\n",
        "\n",
        "class CapsLayer(object):\n",
        "    ''' Capsule layer.\n",
        "    Args:\n",
        "        input: A 4-D tensor.\n",
        "        num_outputs: the number of capsule in this layer.\n",
        "        vec_len: integer, the length of the output vector of a capsule.\n",
        "        layer_type: string, one of 'FC' or \"CONV\", the type of this layer,\n",
        "            fully connected or convolution, for the future expansion capability\n",
        "        with_routing: boolean, this capsule is routing with the\n",
        "                      lower-level layer capsule.\n",
        "\n",
        "    Returns:\n",
        "        A 4-D tensor.\n",
        "    '''\n",
        "    def __init__(self, num_outputs, vec_len, with_routing=True, layer_type='FC'):\n",
        "        self.num_outputs = num_outputs\n",
        "        self.vec_len = vec_len\n",
        "        self.with_routing = with_routing\n",
        "        self.layer_type = layer_type\n",
        "\n",
        "    def __call__(self, input, kernel_size=None, stride=None):\n",
        "        '''\n",
        "        The parameters 'kernel_size' and 'stride' will be used while 'layer_type' equal 'CONV'\n",
        "        '''\n",
        "        if self.layer_type == 'CONV':\n",
        "            self.kernel_size = kernel_size\n",
        "            self.stride = stride\n",
        "\n",
        "            if not self.with_routing:\n",
        "                # the PrimaryCaps layer, a convolutional layer\n",
        "                # input: [batch_size, 20, 20, 256]\n",
        "                # assert input.get_shape() == [cfg.batch_size, 20, 20, 256]\n",
        "\n",
        "                # NOTE: I can't find out any words from the paper whether the\n",
        "                # PrimaryCap convolution does a ReLU activation or not before\n",
        "                # squashing function, but experiment show that using ReLU get a\n",
        "                # higher test accuracy. So, which one to use will be your choice\n",
        "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
        "                                                    self.kernel_size, self.stride, padding=\"VALID\",\n",
        "                                                    activation_fn=tf.nn.relu)\n",
        "                # capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
        "                #                                    self.kernel_size, self.stride,padding=\"VALID\",\n",
        "                #                                    activation_fn=None)\n",
        "                capsules = tf.reshape(capsules, (cfg.batch_size, -1, self.vec_len, 1))\n",
        "\n",
        "                # return tensor with shape [batch_size, 1152, 8, 1]\n",
        "                capsules = squash(capsules)\n",
        "                return(capsules)\n",
        "\n",
        "        if self.layer_type == 'FC':\n",
        "            if self.with_routing:\n",
        "                # the DigitCaps layer, a fully connected layer\n",
        "                # Reshape the input into [batch_size, 1152, 1, 8, 1]\n",
        "                self.input = tf.reshape(input, shape=(cfg.batch_size, -1, 1, input.shape[-2].value, 1))\n",
        "\n",
        "                with tf.variable_scope('routing'):\n",
        "                    # b_IJ: [batch_size, num_caps_l, num_caps_l_plus_1, 1, 1],\n",
        "                    # about the reason of using 'batch_size', see issue #21\n",
        "                    b_IJ = tf.constant(np.zeros([cfg.batch_size, input.shape[1].value, self.num_outputs, 1, 1], dtype=np.float32))\n",
        "                    capsules = routing(self.input, b_IJ, num_outputs=self.num_outputs, num_dims=self.vec_len)\n",
        "                    capsules = tf.squeeze(capsules, axis=1)\n",
        "\n",
        "            return(capsules)\n",
        "\n",
        "\n",
        "def routing(input, b_IJ, num_outputs=10, num_dims=16):\n",
        "    ''' The routing algorithm.\n",
        "\n",
        "    Args:\n",
        "        input: A Tensor with [batch_size, num_caps_l=1152, 1, length(u_i)=8, 1]\n",
        "               shape, num_caps_l meaning the number of capsule in the layer l.\n",
        "        num_outputs: the number of output capsules.\n",
        "        num_dims: the number of dimensions for output capsule.\n",
        "    Returns:\n",
        "        A Tensor of shape [batch_size, num_caps_l_plus_1, length(v_j)=16, 1]\n",
        "        representing the vector output `v_j` in the layer l+1\n",
        "    Notes:\n",
        "        u_i represents the vector output of capsule i in the layer l, and\n",
        "        v_j the vector output of capsule j in the layer l+1.\n",
        "     '''\n",
        "\n",
        "    # W: [1, num_caps_i, num_caps_j * len_v_j, len_u_j, 1]\n",
        "    input_shape = get_shape(input)\n",
        "    W = tf.get_variable('Weight', shape=[1, input_shape[1], num_dims * num_outputs] + input_shape[-2:],\n",
        "                        dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=cfg.stddev))\n",
        "    biases = tf.get_variable('bias', shape=(1, 1, num_outputs, num_dims, 1))\n",
        "\n",
        "    # Eq.2, calc u_hat\n",
        "    # Since tf.matmul is a time-consuming op,\n",
        "    # A better solution is using element-wise multiply, reduce_sum and reshape\n",
        "    # ops instead. Matmul [a, b] x [b, c] is equal to a series ops as\n",
        "    # element-wise multiply [a*c, b] * [a*c, b], reduce_sum at axis=1 and\n",
        "    # reshape to [a, c]\n",
        "    input = tf.tile(input, [1, 1, num_dims * num_outputs, 1, 1])\n",
        "    # assert input.get_shape() == [cfg.batch_size, 1152, 160, 8, 1]\n",
        "\n",
        "    u_hat = reduce_sum(W * input, axis=3, keepdims=True)\n",
        "    u_hat = tf.reshape(u_hat, shape=[-1, input_shape[1], num_outputs, num_dims, 1])\n",
        "    # assert u_hat.get_shape() == [cfg.batch_size, 1152, 10, 16, 1]\n",
        "\n",
        "    # In forward, u_hat_stopped = u_hat; in backward, no gradient passed back from u_hat_stopped to u_hat\n",
        "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
        "\n",
        "    # line 3,for r iterations do\n",
        "    for r_iter in range(cfg.iter_routing):\n",
        "        with tf.variable_scope('iter_' + str(r_iter)):\n",
        "            # line 4:\n",
        "            # => [batch_size, 1152, 10, 1, 1]\n",
        "            c_IJ = softmax(b_IJ, axis=2)\n",
        "\n",
        "            # At last iteration, use `u_hat` in order to receive gradients from the following graph\n",
        "            if r_iter == cfg.iter_routing - 1:\n",
        "                # line 5:\n",
        "                # weighting u_hat with c_IJ, element-wise in the last two dims\n",
        "                # => [batch_size, 1152, 10, 16, 1]\n",
        "                s_J = tf.multiply(c_IJ, u_hat)\n",
        "                # then sum in the second dim, resulting in [batch_size, 1, 10, 16, 1]\n",
        "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
        "                # assert s_J.get_shape() == [cfg.batch_size, 1, num_outputs, num_dims, 1]\n",
        "\n",
        "                # line 6:\n",
        "                # squash using Eq.1,\n",
        "                v_J = squash(s_J)\n",
        "                # assert v_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
        "            elif r_iter < cfg.iter_routing - 1:  # Inner iterations, do not apply backpropagation\n",
        "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
        "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
        "                v_J = squash(s_J)\n",
        "\n",
        "                # line 7:\n",
        "                # reshape & tile v_j from [batch_size ,1, 10, 16, 1] to [batch_size, 1152, 10, 16, 1]\n",
        "                # then matmul in the last tow dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
        "                # batch_size dim, resulting in [1, 1152, 10, 1, 1]\n",
        "                v_J_tiled = tf.tile(v_J, [1, input_shape[1], 1, 1, 1])\n",
        "                u_produce_v = reduce_sum(u_hat_stopped * v_J_tiled, axis=3, keepdims=True)\n",
        "                # assert u_produce_v.get_shape() == [cfg.batch_size, 1152, 10, 1, 1]\n",
        "\n",
        "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
        "                b_IJ += u_produce_v\n",
        "\n",
        "    return(v_J)\n",
        "\n",
        "\n",
        "def squash(vector):\n",
        "    '''Squashing function corresponding to Eq. 1\n",
        "    Args:\n",
        "        vector: A tensor with shape [batch_size, 1, num_caps, vec_len, 1] or [batch_size, num_caps, vec_len, 1].\n",
        "    Returns:\n",
        "        A tensor with the same shape as vector but squashed in 'vec_len' dimension.\n",
        "    '''\n",
        "    vec_squared_norm = reduce_sum(tf.square(vector), -2, keepdims=True)\n",
        "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
        "    vec_squashed = scalar_factor * vector  # element-wise\n",
        "    return(vec_squashed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ANQ7MNaoeX5",
        "colab_type": "text"
      },
      "source": [
        "# capsNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkHCMdwoj83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "License: Apache-2.0\n",
        "Author: Huadong Liao\n",
        "E-mail: naturomics.liao@gmail.com\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "epsilon = 1e-9\n",
        "\n",
        "\n",
        "class CapsNet(object):\n",
        "    def __init__(self, is_training=True, height=28, width=28, channels=1, num_label=10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            height: Integer, the height of inputs.\n",
        "            width: Integer, the width of inputs.\n",
        "            channels: Integer, the channels of inputs.\n",
        "            num_label: Integer, the category number.\n",
        "        \"\"\"\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.channels = channels\n",
        "        self.num_label = num_label\n",
        "\n",
        "        self.graph = tf.Graph()\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            if is_training:\n",
        "                self.X, self.labels = get_batch_data(cfg.batch_size, cfg.num_threads)\n",
        "                self.Y = tf.one_hot(self.labels, depth=self.num_label, axis=1, dtype=tf.float32)\n",
        "\n",
        "                self.build_arch()\n",
        "                self.loss()\n",
        "                self._summary()\n",
        "\n",
        "                # t_vars = tf.trainable_variables()\n",
        "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "                self.optimizer = tf.train.AdamOptimizer()\n",
        "                self.train_op = self.optimizer.minimize(self.total_loss, global_step=self.global_step)\n",
        "            else:\n",
        "                self.X = tf.placeholder(tf.float32, shape=(cfg.batch_size, self.height, self.width, self.channels))\n",
        "                self.labels = tf.placeholder(tf.int32, shape=(cfg.batch_size, ))\n",
        "                self.Y = tf.reshape(self.labels, shape=(cfg.batch_size, self.num_label, 1))\n",
        "                self.build_arch()\n",
        "\n",
        "        tf.logging.info('Seting up the main structure')\n",
        "\n",
        "    def build_arch(self):\n",
        "        with tf.variable_scope('Conv1_layer'):\n",
        "            # Conv1, return tensor with shape [batch_size, 20, 20, 256]\n",
        "            conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
        "                                             kernel_size=9, stride=1,\n",
        "                                             padding='VALID')\n",
        "\n",
        "        # Primary Capsules layer, return tensor with shape [batch_size, 1152, 8, 1]\n",
        "        with tf.variable_scope('PrimaryCaps_layer'):\n",
        "            primaryCaps = CapsLayer(num_outputs=32, vec_len=8, with_routing=False, layer_type='CONV')\n",
        "            caps1 = primaryCaps(conv1, kernel_size=9, stride=2)\n",
        "\n",
        "        # DigitCaps layer, return shape [batch_size, 10, 16, 1]\n",
        "        with tf.variable_scope('DigitCaps_layer'):\n",
        "            digitCaps = CapsLayer(num_outputs=self.num_label, vec_len=16, with_routing=True, layer_type='FC')\n",
        "            self.caps2 = digitCaps(caps1)\n",
        "\n",
        "        # Decoder structure in Fig. 2\n",
        "        # 1. Do masking, how:\n",
        "        with tf.variable_scope('Masking'):\n",
        "            # a). calc ||v_c||, then do softmax(||v_c||)\n",
        "            # [batch_size, 10, 16, 1] => [batch_size, 10, 1, 1]\n",
        "            self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2),\n",
        "                                               axis=2, keepdims=True) + epsilon)\n",
        "            self.softmax_v = softmax(self.v_length, axis=1)\n",
        "            # assert self.softmax_v.get_shape() == [cfg.batch_size, self.num_label, 1, 1]\n",
        "\n",
        "            # b). pick out the index of max softmax val of the 10 caps\n",
        "            # [batch_size, 10, 1, 1] => [batch_size] (index)\n",
        "            self.argmax_idx = tf.to_int32(tf.argmax(self.softmax_v, axis=1))\n",
        "            # assert self.argmax_idx.get_shape() == [cfg.batch_size, 1, 1]\n",
        "            self.argmax_idx = tf.reshape(self.argmax_idx, shape=(cfg.batch_size, ))\n",
        "\n",
        "            # Method 1.\n",
        "            if not cfg.mask_with_y:\n",
        "                # c). indexing\n",
        "                # It's not easy to understand the indexing process with argmax_idx\n",
        "                # as we are 3-dim animal\n",
        "                masked_v = []\n",
        "                for batch_size in range(cfg.batch_size):\n",
        "                    v = self.caps2[batch_size][self.argmax_idx[batch_size], :]\n",
        "                    masked_v.append(tf.reshape(v, shape=(1, 1, 16, 1)))\n",
        "\n",
        "                self.masked_v = tf.concat(masked_v, axis=0)\n",
        "                assert self.masked_v.get_shape() == [cfg.batch_size, 1, 16, 1]\n",
        "            # Method 2. masking with true label, default mode\n",
        "            else:\n",
        "                self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, self.num_label, 1)))\n",
        "                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, keepdims=True) + epsilon)\n",
        "\n",
        "        # 2. Reconstructe the MNIST images with 3 FC layers\n",
        "        # [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]\n",
        "        with tf.variable_scope('Decoder'):\n",
        "            vector_j = tf.reshape(self.masked_v, shape=(cfg.batch_size, -1))\n",
        "            fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512)\n",
        "            fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
        "            self.decoded = tf.contrib.layers.fully_connected(fc2,\n",
        "                                                             num_outputs=self.height * self.width * self.channels,\n",
        "                                                             activation_fn=tf.sigmoid)\n",
        "\n",
        "    def loss(self):\n",
        "        # 1. The margin loss\n",
        "\n",
        "        # [batch_size, 10, 1, 1]\n",
        "        # max_l = max(0, m_plus-||v_c||)^2\n",
        "        max_l = tf.square(tf.maximum(0., cfg.m_plus - self.v_length))\n",
        "        # max_r = max(0, ||v_c||-m_minus)^2\n",
        "        max_r = tf.square(tf.maximum(0., self.v_length - cfg.m_minus))\n",
        "        assert max_l.get_shape() == [cfg.batch_size, self.num_label, 1, 1]\n",
        "\n",
        "        # reshape: [batch_size, 10, 1, 1] => [batch_size, 10]\n",
        "        max_l = tf.reshape(max_l, shape=(cfg.batch_size, -1))\n",
        "        max_r = tf.reshape(max_r, shape=(cfg.batch_size, -1))\n",
        "\n",
        "        # calc T_c: [batch_size, 10]\n",
        "        # T_c = Y, is my understanding correct? Try it.\n",
        "        T_c = self.Y\n",
        "        # [batch_size, 10], element-wise multiply\n",
        "        L_c = T_c * max_l + cfg.lambda_val * (1 - T_c) * max_r\n",
        "\n",
        "        self.margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1))\n",
        "\n",
        "        # 2. The reconstruction loss\n",
        "        orgin = tf.reshape(self.X, shape=(cfg.batch_size, -1))\n",
        "        squared = tf.square(self.decoded - orgin)\n",
        "        self.reconstruction_err = tf.reduce_mean(squared)\n",
        "\n",
        "        # 3. Total loss\n",
        "        # The paper uses sum of squared error as reconstruction error, but we\n",
        "        # have used reduce_mean in `# 2 The reconstruction loss` to calculate\n",
        "        # mean squared error. In order to keep in line with the paper,the\n",
        "        # regularization scale should be 0.0005*784=0.392\n",
        "        self.total_loss = self.margin_loss + cfg.regularization_scale * self.reconstruction_err\n",
        "\n",
        "    # Summary\n",
        "    def _summary(self):\n",
        "        train_summary = []\n",
        "        train_summary.append(tf.summary.scalar('train/margin_loss', self.margin_loss))\n",
        "        train_summary.append(tf.summary.scalar('train/reconstruction_loss', self.reconstruction_err))\n",
        "        train_summary.append(tf.summary.scalar('train/total_loss', self.total_loss))\n",
        "        recon_img = tf.reshape(self.decoded, shape=(cfg.batch_size, self.height, self.width, self.channels))\n",
        "        train_summary.append(tf.summary.image('reconstruction_img', recon_img))\n",
        "        self.train_summary = tf.summary.merge(train_summary)\n",
        "\n",
        "        correct_prediction = tf.equal(tf.to_int32(self.labels), self.argmax_idx)\n",
        "        self.accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2c47XQtVjMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Delete All flags before running\n",
        "\n",
        "# def del_all_flags(FLAGS):\n",
        "#     flags_dict = FLAGS._flags()    \n",
        "#     keys_list = [keys for keys in flags_dict]    \n",
        "#     for keys in keys_list:\n",
        "#         FLAGS.__delattr__(keys)\n",
        "\n",
        "# del_all_flags(tf.flags.FLAGS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gdsP4XjooMy",
        "colab_type": "text"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBJfR97Roq4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "flags = tf.app.flags\n",
        "\n",
        "\n",
        "############################\n",
        "#    hyper parameters      #\n",
        "############################\n",
        "\n",
        "# For separate margin loss\n",
        "flags.DEFINE_float('m_plus', 0.9, 'the parameter of m plus')\n",
        "flags.DEFINE_float('m_minus', 0.1, 'the parameter of m minus')\n",
        "flags.DEFINE_float('lambda_val', 0.5, 'down weight of the loss for absent digit classes')\n",
        "\n",
        "# for training\n",
        "flags.DEFINE_integer('batch_size', 32, 'batch size')\n",
        "flags.DEFINE_integer('epoch', 10, 'epoch')\n",
        "flags.DEFINE_integer('iter_routing', 5, 'number of iterations in routing algorithm')\n",
        "flags.DEFINE_boolean('mask_with_y', True, 'use the true label to mask out target capsule or not')\n",
        "\n",
        "flags.DEFINE_float('stddev', 0.01, 'stddev for W initializer')\n",
        "flags.DEFINE_float('regularization_scale', 0.392, 'regularization coefficient for reconstruction loss, default to 0.0005*784=0.392')\n",
        "\n",
        "\n",
        "############################\n",
        "#   environment setting    #\n",
        "############################\n",
        "flags.DEFINE_boolean('is_training', True, 'train or predict phase')\n",
        "flags.DEFINE_integer('num_threads', 8, 'number of threads of enqueueing examples')\n",
        "flags.DEFINE_string('logdir', 'logdir', 'logs directory')\n",
        "flags.DEFINE_integer('train_sum_freq', 50, 'the frequency of saving train summary(step)')\n",
        "flags.DEFINE_integer('val_sum_freq', 500, 'the frequency of saving valuation summary(step)')\n",
        "flags.DEFINE_integer('save_freq', 3, 'the frequency of saving model(epoch)')\n",
        "flags.DEFINE_string('results', 'results', 'path for saving results')\n",
        "\n",
        "############################\n",
        "#   distributed setting    #\n",
        "############################\n",
        "flags.DEFINE_integer('num_gpu', 4, 'number of gpus for distributed training')\n",
        "flags.DEFINE_integer('batch_size_per_gpu', 128, 'batch size on 1 gpu')\n",
        "flags.DEFINE_integer('thread_per_gpu', 4, 'Number of preprocessing threads per tower.')\n",
        "\n",
        "cfg = tf.app.flags.FLAGS\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzFdMr1Wo1AX",
        "colab_type": "text"
      },
      "source": [
        "# Main Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnAxG1zdo0lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to():\n",
        "    if not os.path.exists(cfg.results):\n",
        "        os.mkdir(cfg.results)\n",
        "    if cfg.is_training:\n",
        "        loss = cfg.results + '/loss.csv'\n",
        "        train_acc = cfg.results + '/train_acc.csv'\n",
        "        val_acc = cfg.results + '/val_acc.csv'\n",
        "\n",
        "        if os.path.exists(val_acc):\n",
        "            os.remove(val_acc)\n",
        "        if os.path.exists(loss):\n",
        "            os.remove(loss)\n",
        "        if os.path.exists(train_acc):\n",
        "            os.remove(train_acc)\n",
        "\n",
        "        fd_train_acc = open(train_acc, 'w')\n",
        "        fd_train_acc.write('step,train_acc\\n')\n",
        "        fd_loss = open(loss, 'w')\n",
        "        fd_loss.write('step,loss\\n')\n",
        "        fd_val_acc = open(val_acc, 'w')\n",
        "        fd_val_acc.write('step,val_acc\\n')\n",
        "        return(fd_train_acc, fd_loss, fd_val_acc)\n",
        "    else:\n",
        "        test_acc = cfg.results + '/test_acc.csv'\n",
        "        if os.path.exists(test_acc):\n",
        "            os.remove(test_acc)\n",
        "        fd_test_acc = open(test_acc, 'w')\n",
        "        fd_test_acc.write('test_acc\\n')\n",
        "        return(fd_test_acc)\n",
        "\n",
        "\n",
        "def train(model, supervisor, num_label):\n",
        "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(cfg.batch_size, is_training=True)\n",
        "    Y = valY[:num_val_batch * cfg.batch_size].reshape((-1, 1))\n",
        "\n",
        "    fd_train_acc, fd_loss, fd_val_acc = save_to()\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    with supervisor.managed_session(config=config) as sess:\n",
        "        print(\"\\nNote: all of results will be saved to directory: \" + cfg.results)\n",
        "        for epoch in range(cfg.epoch):\n",
        "            print(\"Training for epoch %d/%d:\" % (epoch, cfg.epoch))\n",
        "            if supervisor.should_stop():\n",
        "                print('supervisor stoped!')\n",
        "                break\n",
        "            for step in tqdm(range(num_tr_batch), total=num_tr_batch, ncols=70, leave=False, unit='b'):\n",
        "                start = step * cfg.batch_size\n",
        "                end = start + cfg.batch_size\n",
        "                global_step = epoch * num_tr_batch + step\n",
        "\n",
        "                if global_step % cfg.train_sum_freq == 0:\n",
        "                    _, loss, train_acc, summary_str = sess.run([model.train_op, model.total_loss, model.accuracy, model.train_summary])\n",
        "                    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
        "                    supervisor.summary_writer.add_summary(summary_str, global_step)\n",
        "\n",
        "                    print(\"Global step: {}\".format(str(global_step)) + ',' + \"loss: {}\".format(str(loss)) + \"\\n\")\n",
        "\n",
        "\n",
        "                    fd_loss.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
        "                    fd_loss.flush()\n",
        "                    fd_train_acc.write(str(global_step) + ',' + str(train_acc / cfg.batch_size) + \"\\n\")\n",
        "                    fd_train_acc.flush()\n",
        "                else:\n",
        "                    sess.run(model.train_op)\n",
        "\n",
        "                if cfg.val_sum_freq != 0 and (global_step) % cfg.val_sum_freq == 0:\n",
        "                    val_acc = 0\n",
        "                    for i in range(num_val_batch):\n",
        "                        start = i * cfg.batch_size\n",
        "                        end = start + cfg.batch_size\n",
        "                        acc = sess.run(model.accuracy, {model.X: valX[start:end], model.labels: valY[start:end]})\n",
        "                        val_acc += acc\n",
        "                    val_acc = val_acc / (cfg.batch_size * num_val_batch)\n",
        "                    print(\"Global Step: \"+str(global_step) + ',' + \"val_acc: \"+ str(val_acc) + '\\n')\n",
        "                    fd_val_acc.write(str(global_step) + ',' + str(val_acc) + '\\n')\n",
        "                    fd_val_acc.flush()\n",
        "\n",
        "            if (epoch + 1) % cfg.save_freq == 0:\n",
        "                supervisor.saver.save(sess, cfg.logdir + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
        "\n",
        "        fd_val_acc.close()\n",
        "        fd_train_acc.close()\n",
        "        fd_loss.close()\n",
        "\n",
        "\n",
        "def evaluation(model, supervisor, num_label):\n",
        "    teX, teY, num_te_batch = load_data(cfg.batch_size, is_training=False)\n",
        "    fd_test_acc = save_to()\n",
        "    with supervisor.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
        "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(cfg.logdir))\n",
        "        tf.logging.info('Model restored!')\n",
        "\n",
        "        test_acc = 0\n",
        "        for i in tqdm(range(num_te_batch), total=num_te_batch, ncols=70, leave=False, unit='b'):\n",
        "            start = i * cfg.batch_size\n",
        "            end = start + cfg.batch_size\n",
        "            acc = sess.run(model.accuracy, {model.X: teX[start:end], model.labels: teY[start:end]})\n",
        "            test_acc += acc\n",
        "        test_acc = test_acc / (cfg.batch_size * num_te_batch)\n",
        "        fd_test_acc.write(str(test_acc))\n",
        "        fd_test_acc.close()\n",
        "        print('\\nTest Accuracy is {}:'.format(test_acc))\n",
        "        print('\\nTest accuracy has been saved to ' + cfg.results + '/test_acc')\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKoYiZzjaohA",
        "colab_type": "text"
      },
      "source": [
        "# Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKlyEnFD0RP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.is_training=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwTLpHcJ0Q9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "9b08cabe-64c9-4dfe-a0c2-b3c1f269e2e8"
      },
      "source": [
        "def main(_):\n",
        "    tf.logging.info(' Loading Graph...')\n",
        "    num_label = 10\n",
        "    model = CapsNet()\n",
        "    tf.logging.info(' Graph loaded')\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "\n",
        "    sv = tf.train.Supervisor(graph=model.graph, logdir=cfg.logdir, save_model_secs=0)\n",
        "\n",
        "    if cfg.is_training:\n",
        "        tf.logging.info(' Start training...')\n",
        "        train(model, sv, num_label)\n",
        "        tf.logging.info('Training done')\n",
        "    else:\n",
        "        evaluation(model, sv, num_label)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tf.app.run()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: Loading Graph...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:09:58.352348 140319578068864 <ipython-input-13-fda5935e9628>:2]  Loading Graph...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Seting up the main structure\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:09:59.906388 140319578068864 <ipython-input-6-4752a8a30df1>:46] Seting up the main structure\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: Graph loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:09:59.909253 140319578068864 <ipython-input-13-fda5935e9628>:5]  Graph loaded\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from logdir/model_epoch_0008_step_15461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:00.385176 140319578068864 saver.py:1284] Restoring parameters from logdir/model_epoch_0008_step_15461\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W1101 08:10:00.714938 140319578068864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:00.727056 140319578068864 session_manager.py:500] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:00.756721 140319578068864 session_manager.py:502] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting standard services.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:34.271227 140319578068864 supervisor.py:737] Starting standard services.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting queue runners.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:34.945167 140319578068864 supervisor.py:743] Starting queue runners.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from logdir/model_epoch_0008_step_15461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:34.976254 140319578068864 saver.py:1284] Restoring parameters from logdir/model_epoch_0008_step_15461\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Model restored!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:36.736618 140319578068864 <ipython-input-9-c121f0c92096>:91] Model restored!\n",
            "  7%|██▎                              | 23/320 [00:01<00:16, 17.95b/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Recording summary at step 15462.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1101 08:10:38.249198 140316312876800 supervisor.py:1050] Recording summary at step 15462.\n",
            "                                                                      "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy is 0.80576171875:\n",
            "\n",
            "Test accuracy has been saved to results/test_acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spYdQXFr1UbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}